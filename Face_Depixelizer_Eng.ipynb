{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Face Depixelizer Eng",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ctawong/Face-Depixelizer/blob/master/Face_Depixelizer_Eng.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "siqzcgRRyr_n",
        "colab_type": "text"
      },
      "source": [
        "<b><font color=\"black\" size=\"+4\">Try PULSE</font></b>\n",
        "\n",
        "Given a low-resolution input image, Face Depixelizer searches the outputs of a generative model (here, StyleGAN) for high-resolution images that are perceptually realistic and downscale correctly.\n",
        "\n",
        "<b><font color=\"black\" size=\"+2\">Based on:</font></b>\n",
        "\n",
        "**GitHub repository**: [PULSE](https://github.com/adamian98/pulse)\n",
        "\n",
        "Article: [PULSE: Self-Supervised Photo Upsampling via Latent Space Exploration of Generative Models](https://arxiv.org/abs/2003.03808)\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fU0aGtD4Nl4W",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torchvision\n",
        "from pathlib import Path\n",
        "import shutil\n",
        "import os\n",
        "\n",
        "if not Path(\"PULSE.py\").exists():\n",
        "  if Path(\"pulse\").exists():\n",
        "    %cd /content/pulse\n",
        "  else:\n",
        "    !git clone https://github.com/ctawong/pulse\n",
        "    %cd /content/pulse\n",
        "    !mkdir input/\n",
        "    toPIL = torchvision.transforms.ToPILImage()\n",
        "    toTensor = torchvision.transforms.ToTensor()\n",
        "    from bicubic import BicubicDownSample\n",
        "    D = BicubicDownSample(factor=1)\n",
        "\n",
        "# remove previous content\n",
        "if Path(\"realpics\").exists():\n",
        "  shutil.rmtree('realpics')\n",
        "!mkdir realpics\n",
        "if Path(\"input\").exists():\n",
        "  shutil.rmtree('input')\n",
        "!mkdir input\n",
        "\n",
        "\n",
        "from io import BytesIO\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "from PIL import Image\n",
        "from PULSE import PULSE\n",
        "from google.colab import files\n",
        "from bicubic import BicubicDownSample\n",
        "from IPython import display\n",
        "from IPython.display import display\n",
        "from IPython.display import clear_output\n",
        "import numpy as np\n",
        "from drive import open_url\n",
        "from mpl_toolkits.axes_grid1 import ImageGrid\n",
        "import requests\n",
        "%matplotlib inline\n",
        "\n",
        "#@markdown <- Paste **photo url** below and click play button on left to start!\n",
        "\n",
        "#@markdown ---\n",
        "#@markdown ## Required settings:\n",
        "Photo_URL = \"\" #@param {type:\"string\"}\n",
        "r = requests.get(Photo_URL, allow_redirects=True)\n",
        "ext=r.headers.get('content-type').split('/')[1]\n",
        "realPicName = 'realpics/face.'+ext\n",
        "open(realPicName, 'wb').write(r.content)\n",
        "\n",
        "!python align_face.py\n",
        "!mv input/face_0.png input/face.png\n",
        "\n",
        "# face = Image.open(fn)\n",
        "# face = face.resize((1024, 1024), Image.ANTIALIAS)\n",
        "# face = face.convert('RGB')\n",
        "# face_name = 'face.png'\n",
        "# face.save(face_name)\n",
        "# %cp $face_name /content/pulse/input/\n",
        "\n",
        "# images = []\n",
        "# imagesHR = []\n",
        "# imagesHR.append(face)\n",
        "# face = toPIL(D(toTensor(face).unsqueeze(0).cuda()).cpu().detach().clamp(0,1)[0])\n",
        "# images.append(face)\n",
        "\n",
        "\n",
        "#@markdown ---\n",
        "#@markdown ## Advanced settings:\n",
        "#@markdown ##### *If you want to make a more accurate result, then modify the following* **DEFAULT** *variables*:\n",
        "\n",
        "allowed_error = 0.0035 #@param {type:\"slider\", min:0.001, max:0.006, step:0.0005}\n",
        "number_of_steps = 150 #@param {type:\"slider\", min:100, max:1000, step:50}\n",
        "seed = 100 #@param {type:\"integer\"}\n",
        "noise_type = 'trainable'  #@param ['zero', 'fixed', 'trainable']\n",
        "optimizer = 'adam'  #@param ['sgd', 'adam','sgdm', 'adamax']\n",
        "learning_rate = 0.4 #@param {type:\"slider\", min:0, max:1, step:0.05}\n",
        "learning_rate_schedule = 'linear1cycledrop'  #@param ['fixed', 'linear1cycle', 'linear1cycledrop']\n",
        "clear_output()\n",
        "\n",
        "seed = abs(seed)\n",
        "!python run.py \\\n",
        "  -eps $allowed_error\\\n",
        "  -seed $seed \\\n",
        "  -noise_type $noise_type \\\n",
        "  -opt_name $optimizer \\\n",
        "  -learning_rate $learning_rate \\\n",
        "  -steps $number_of_steps \\\n",
        "  -lr_schedule $learning_rate_schedule\n",
        "\n",
        "fig, (ax1, ax2) = plt.subplots(1, 2)\n",
        "ax1.imshow(mpimg.imread('/content/pulse/input/face.png'))\n",
        "ax1.set_title('Original')\n",
        "\n",
        "if Path('/content/pulse/runs/face.png').exists():\n",
        "  ax2.imshow(mpimg.imread('/content/pulse/runs/face.png'))\n",
        "  ax2.set_title('Result')\n",
        "else:\n",
        "  print(\"Error: Try increasing allowed_error and/or number_of_steps\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V78mfR3QKiw_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Path('/content/pulse/runs/face.png').exists()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DUfP6_7vTK3b",
        "colab_type": "code",
        "cellView": "both",
        "colab": {}
      },
      "source": [
        "#@title <b><font color=\"red\" size=\"+3\">‚Üê</font><font color=\"black\" size=\"+3\"> Download result</font></b>\n",
        "try: files.download('/content/pulse/runs/face.png')\n",
        "except: raise Exception(\"No result image\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}